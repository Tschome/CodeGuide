# Audio音频



## 声音定义

声音是通过空气传播的一种连续的振动波，具有幅度和频率。物体的振动引起空气的震荡，人耳对这种震荡的感觉。声音用电信号表示时，声音信号在时间和幅度上都是连续的模拟信号。

## 声卡

声卡的结构

一般来说，一块完整的声卡要由控制芯片（AIC）、DSP和CODEC、功放芯片、各种端口等部分组成。
控制芯片是声卡的灵魂，它的任务是负责处理、控制音频数字信号，一块声卡支持哪些功能基本上取决于控制芯片的“能力”。

DSP是声卡中的加速芯片，它要负责对信号进行运算，然后生成各种音效。 

声卡上的CODEC芯片负责数字信号与模拟信号之间的互相转换，严格来说，它包含DAC（数字→模拟）和ADC（模拟→数字）两部分。 

功放芯片即声音放大芯片，功能就是功率放大以推动喇叭发声工作。 

声音输入/输出端口较简单，它起的作用就是音频信号的输入和输出。 



## 声道

   声道被认为是一个滤波器，有许多共振峰，其频率受随时间变化的声道形状所控制，例如舌的移动就会改变声道的形状。许多话音编码器用一个短期滤波器(short term filter)来模拟声道。

- 单声道(Monophonic) ：

  ​		单声道意味着单个声源，单声道是比较原始的声音复制形式。在通过两个扬声器回放单声道信息的时候，就可以明显感觉到声音是从两个音箱中间传递到耳朵里的。此声道缺乏位置感。

- 立体声(Stereophonic) ：

  ​		立体声又称为双声道，在录制过程中单声道声音被分配到两个独立的声道，从而达到了很好的声音定位效果，如图所示为一款立体声音箱。单声道缺乏对声音的位置定位，而立体声技术则彻底改变了这一状况。这种技术在音乐欣赏中显得尤为有用，听众可以清晰地分辨出各种乐器来自何方，从而使音乐更富想象力，更加接近于临场感受。立体声并不表示有两个声源，立体声指的是三维听觉效果。

- 四声道环绕：

  ​		又称为4.1声道，即4声道+低音声道。四声道环绕规定了4个发音点：前左、前右、后左、后右，听众则被包围在这中间。同时还建议增加一个低音音箱，以加强对低频信号的回放处理，如图所示。就整体效果而言，四声道系统可以为听众带来来自多个不同方向的声音环绕，可以获得身临其境的听觉感受，给用户以全新的体验。

- 5.1声道：

  ​		5.1声道已广泛运用于各类影院和家庭影院中，一些比较知名的声音录制压缩格式，例如杜比AC-3（Dolby Digital）、DTS等都是以5.1声音系统为技术蓝本的。其中“.1”声道是一个专门设计的超低音声道，即LFE声道，LFE (low frequency effects)是低频音效的加强声道。这一声道可以产生频响范围为20～120Hz的超低音。其实5.1声音系统来源于4.1环绕，只是在原来的基础上增加了一个中置单元。中置单元负责传送低于80Hz的声音信号，在欣赏影片时有利于加强人声，把对话集中在整个声场的中部，以增加整体效果。中央声道大部份时间负责重放人物对白的部份；前置主左/右声道则是用来弥补在屏幕中央以外或不能从屏幕看到的动作及其它声音；后置环绕音效则是负责外围及整个背景音乐，让人感觉置身于整个场景的正中央，万马奔腾的震撼、喷射机从头顶呼啸而过的效果，就是拜它所赐；而马达声、轰炸机的声音或是大鼓等震人心弦的重低音，则是由重低音喇叭一手包办。

- 7.1声道：7.1声道系统的作用简单来说就是在听者的周围建立起一套前后声场相对平衡的声场,不同于5.1声道声场的是,它在原有的基础上增加了后中声场声道,同时它也不同于普通6.1声道声场,因为7.1声道有双路后中置,而这双路后中置的最大作用就是为了防止听者因为没有坐在皇帝位而在听觉上产生声场的偏差。因为人的耳朵分左右两个，这时如果你的后面只有一个中置喇叭，声场就会有所偏差，这个偏差会造成有时你觉得声音是比较靠近左边，因为你左耳先收到声音，有时又会觉得声音在右边，而且声场不会有立体感，几乎是很平面的声音，听起来不对劲。道理是:当你的耳朵正面不是正对着发音点时，你需要两只喇叭来修正相位差，这是为什么听音乐要至少用两只喇叭（立体声）。

## 编解码

通常的把音频的采样过程叫做脉冲编码调制编码（PCM）。因音频信号为模拟信号，通过PCM的三部曲（采样、量化、编码）转换成数字信号。

## PCM（脉冲编码调制）

pcm将人听到的模拟信号转换为数字信号的技术。

原理：用一个固定的频率对模拟信号进行采样，采样后的信号在波形上看是遗传连续的幅度不一的脉冲（脉搏短暂欺负的点重启，把这些脉冲的幅值按照一定的精度进行量化，这些量化后的数值被连续的输出、传输、处理或记录到存储介质中，所有这些组成了数字音频的产生过程（抽样、量化、编码三个过程）。

描述PCM的6个参数：

- Sample Rate : 采样频率。

  ​		采样频率(fs)是指每秒钟需要采集多少个声音样本。采样频率越高，播放出的声音质量就越真实越自然。采样频率和采样位数直接决定了声音的效果。

  目前常见的音频信号的频率范围： 

  > 电话信号的频带为200 Hz～3.4 kHz， 
  >
  > 调幅广播(AM)信号的频带为50 Hz～7 kHz， 
  >
  > 调频广播(FM)信号的频带为20 Hz～15 kHz，
  >
  >  高保真音频信号的频带为10 Hz～20 kHz。 

  ​		根据不同的音频信源和应用目标， 可采用不同的采样频率， 如8 kHz、 11.025 kHz、 22.05 kHz、 16 kHz、 37.8 kHz、 44.1 kHz或48 kHz等都是典型的采样频率值。其中，22KHz相当于普通FM广播的音质，44KHz相当于CD播放器播放CD光盘的音质。

  > 注：采样频率是在每个声道上的采样速率，不是在所有频道的采样速率。 因此，要是采样速率是44100 ，那么双声道，采集的样本个数应该是88200个。

- Sample Size : 量化位数。

  ​		样本大小是用每个声音样本的位数bit/s(即bit per sample，bps)表示的，它反映度量声音波形幅度的精度。例如，每个声音样本用16位(2字节)表示，测得的声音样本值是在0～65535的范围里，它的精度就是输入信号的1/65536。样本位数的大小影响到声音的质量，位数越多，声音的质量越高，而需要的存储空间也越多；位数越少，声音的质量越低，需要的存储空间越少。

- Number of Channels : 通道个数。常见的音频有立体声(stereo)和单声道(mono)两种类型，立体声包含左声道和右声道。另外还有环绕立体声等其它不太常用的类型。

- Sign : 表示样本数据是否是有符号位，比如用一字节表示的样本数据，有符号的话表示范围为-128 ~ 127，无符号是0 ~ 255。

- Byte Ordering : 字节序。字节序是little-endian还是big-endian。通常均为little-endian。字节序说明见第4节。

- Integer Or Floating Point : 整形或浮点型。大多数格式的PCM样本数据使用整形表示，而在一些对精度要求高的应用方面，使用浮点类型表示PCM样本数据。

## 码率

也称为比特率，是指每秒传送的bit数。单位为 bps(Bit Per Second)，比特率越高，每秒传送数据就越多，音质就越好。

码率计算公式：

码率 = 采样率 * 采样大小（精度） * 声道数

比如采样率44.1kHz，采样大小为16bit，双声道PCM编码的WAV文件：

码率=44.1kHz×16bit×2=1411.2kbit/s。

那么录制1分钟的音乐的大小为(1411.2 * 1000 * 60) / 8 / 1024 / 1024 = 10.09M。



> 我们先来看看比特率中的数字和字母到底是什么意思？
>
> 首先128k的全称“128kbps”，128kbps就是128kb/s。也就是每秒128kb。请注意，这里的b是小写的b，也就是位。
>
> 知道了这个，我们就能算出来128kb的文件大概占用多少的存储空间：
>
> 128*1000=128000b/s÷8=16000B/s÷1024=15.625KB/s
>
> 15.625KB/s*60=937.5KB/分钟÷1024=0.9155MB/分钟
> 所以，128kb的音频文件，大概每分钟长度的大小都在0.92M或者916kb左右。
>
> 注意b和B是不同的概念
> 

## 音频压缩编码

编码就是一个压缩的过程。

PCM又可以称为未压缩的采样编码。以常见的16KHz采样频率16-bit采样精度为例，1秒就会有32000（2-bit *16000）字节。如果直接将采样值保存或者发送，会占用很大的存储空间和流量。为了节省存储空间以及传输带宽（流量），会对PCM数据进行压缩，也就出现了压缩编解码。

下面列举了常见的压缩编码方式：

> ###### 有损压缩
>
> ​	波形编码：
>
> ​					增量调制：LDM、ADM
>
> ​					脉冲编码调制：PCM、DPCM、ADPCM
>
> ​					子带编码：SBS
>
> ​	参数编码：LPC
>
> ​	混合编码：多脉冲线性预测（MPLPC）、码激励线性预测（MPLPC）
>
> ###### 无损压缩
>
> ​	Huffman编码
>
> ​	行程编码

### 无损压缩和有损压缩

把PCM数据压缩后无任何损伤叫无损压缩，不过压缩程度不高。把PCM数据压缩后有损伤叫有损压缩，最多可以压到几十分之一，不过音频质量差些。

#### 有损压缩

这种压缩的主要方法是去除采集到的音频冗余信息，这些被删除掉的音频信号是没法恢复的，所以称为有损压缩。

冗余信息包括人类听觉范围(20Hz-20000Hz)之外的音频信号和被遮蔽掉的音频信号。什么是被掩蔽的信号呢？信号的掩蔽分为频域掩蔽和时域掩蔽。

(1)频域遮蔽效应

人类听觉范围是20-20000Hz，但这并不意味着只要是这个频率范围内的声音都可以听到，能否听到还与声音的分贝大小有关，有个分贝临界值，高于这个临界值的声音才能听到，低于这个临界值的声音就听不到，在不同的频率下这个临界值是不一样的。

还有一种情况，比如2个音调差不多的人同时说话，一个声音很大，一个声音很小，声音小的会受到声音大的影响，导致声音小的无法被听到。一个很大的声音，它会产生掩蔽效应将与它频率相近的小分贝的声音给掩蔽掉。

(2) 时域遮蔽效应

在时间上相邻的声音之间也有掩蔽现象，称为时域掩蔽。时域掩蔽又分为超前掩蔽和滞后掩蔽。产生时域掩蔽的主要原因是人的大脑处理信息需要花费一定的时间。

一般来说，超前掩蔽很短，只有大约5～20ms，而滞后掩蔽可以持续50～200ms。

#### 无损压缩

将人类无法识别的声音信号删除掉后，对剩余的声音信号继续进行压缩编码，经过这种压缩后再还原时是可以复原到和原来一样的数据的(当然，复原也只是复原到压缩前的状态，那些删除的人类无法识别的部分是不能复原的)，所以称为无损压缩。

### 常见的编解码器

常见的音频编解码器包括OPUS、AAC、Vorbis、Speex、iLBC、AMR、G.711等。

性能上来看，OPUS > AAC > Vorbis。

### 常见的编码格式

1. WAV(无损)

WAV编码就是在PCM数据格式的前面加上44字节，分别用来描述PCM的采样率、声道数、数据格式等信息。

特点：音质非常好，大量软件都支持。

缺点：因为没用经过压缩，所以文件占用的储存空间会特别大。

适用场合：多媒体开发的中间文件、保存音乐和音效素材。

2. MP3(有损)

MP3具有不错的压缩比，使用LAME编码（MP3编码格式的一种实现）的中高码率的MP3文件，听感上非常接近源WAV文件。现如今市面上的音乐大多是这种编码格式。

特点：音质在128Kbit/s以上表现还不错，压缩比比较高，大量软件和硬件都支持，兼容性好。
缺点：由于技术比较落后，同样码率下音质会比AAC、OGG差一些。

3. AAC(有损)

AAC是新一代的音频有损压缩技术，它通过一些附加的编码技术（比如PS、SBR等），衍生出了LC-AAC、HE-AAC、HE-AAC v2三种主要的编码格式。

LC-AAC是比较传统的AAC，相对而言，其主要应用于中高码率场景的编码（≥80Kbit/s）；

HE-AAC（相当于AAC+SBR）主要应用于中低码率场景的编码（≤80Kbit/s）；

而新近推出的HE-AAC v2（相当于AAC+SBR+PS）主要应用于低码率场景的编码（≤48Kbit/s）。事实上大部分编码器都设置为≤48Kbit/s自动启用PS技术，而>48Kbit/s则不加PS，相当于普通的HE-AAC。

特点：在小于128Kbit/s的码率下表现优异，并且多用于视频中的音频编码。
不足：虽然在低码率上表现比MP3好一些，但是还没有达到全面碾压的地步。

适用场合：128Kbit/s以下的音频编码，多用于视频中音频轨的编码。

AAC格式主要分为两种：ADIF、ADTS。

ADIF：Audio Data Interchange Format。 音频数据交换格式。这种格式的特征是可以确定的找到这个音频数据的开始，不能在音频数据流中间开始的解码，即它的解码必须在明确定义的开始处进行。这种格式常用在磁盘文件中。

ADTS：Audio Data Transport Stream。 音频数据传输流。这种格式的特征是它是一个有同步字的比特流，解码可以在这个流中任何位置开始。它的特征类似于mp3数据流格式。

ADTS可以在任意帧解码，它每一帧都有头信息。ADIF只有一个统一的头，所以必须得到所有的数据后解码。且这两种的header的格式也是不同的，目前一般编码后的都是ADTS格式的音频流。

4. Ogg(有损)

Ogg是一种非常有潜力的编码，在各种码率下都有比较优秀的表现，尤其是在中低码率场景下。Ogg除了音质好之外，还是完全免费的，这为Ogg获得更多的支持打好了基础。Ogg有着非常出色的算法，可以用更小的码率达到更好的音质，128Kbit/s的Ogg比192Kbit/s甚至更高码率的MP3还要出色。但目前因为还没有媒体服务软件的支持，因此基于Ogg的数字广播还无法实现。Ogg目前受支持的情况还不够好，无论是软件上的还是硬件上的支持，都无法和MP3相提并论。

特点：可以用比MP3更小的码率实现比MP3更好的音质，高中低码率下均有良好的表现。
缺点：兼容性不够好，流媒体特性不支持。

适用场合：语音聊天的音频消息场景。

5.FLAC(无损)

FLAC是一套著名的自由音频压缩编码，其特点是无损压缩。不同于其他有损压缩编码如MP3 及AAC，它不会破坏任何原有的音频资讯，所以可以还原音乐光盘音质。2012年以来它已被很多软件及硬件音频产品（如CD等）所支持.

FLAC与MP3不同，MP3是音频压缩编码，但FLAC是无损压缩，也就是说音频以FLAC编码压缩后不会丢失任何信息，将FLAC文件还原为WAV文件后，与压缩前的WAV文件内容相同。这种压缩与ZIP的方式类似，但FLAC的压缩比率大于ZIP和RAR，因为FLAC是专门针对PCM音频的特点设计的压缩方式。而且可以使用播放器直接播放FLAC压缩的文件，就象通常播放你的MP3文件一样.

### 音频帧

​        对采样率为44.1kHz的AAC（Advanced Audio Coding）音频进行解码时，一帧的解码时间须控制在23.22毫秒内。通常是按1024个采样点一帧。
​        为什么这里需要说下音频帧呢？
​        音频的帧的概念没有视频帧那么清晰，几乎所有视频编码格式都可以简单的认为一帧就是编码后的一副图像。但音频帧跟编码格式相关，它是各个编码标准自己实现的。因为如果以PCM（未经编码的音频数据）来说，它根本就不需要帧的概念，根据采样率和采样精度就可以播放了。比如采样率为44.1kHZ，采样精度为16位的音频，你可以算出bitrate（比特率）是44100×16bps，每秒的音频数据是固定的44100×16/8 字节。
​        但是我们不希望每一次采样都返回给我们进行处理，我们希望的是返回一段时间内的所有采样数据。这里的音频帧就是每次返回给我们多少个采样数据，一般情况是下返回2048个采样数据。
​        那么单声道 采用16位采样位数 2048个采样数据的大小是多少呢  2048×16/8 = 4096字节。

## 音频的算法处理

主要包含：降噪NS，回声消除AEC，高通滤波HPF，重采样，静音检测，混音算法，延时敏感，卡顿敏感等

### 回声消除

从通讯回音产生的原因看，可以分为声学回音（Acoustic Echo）和线路回音（Line Echo），相应的回声消除技术就叫声学回声消除（Acoustic Echo Cancellation，AEC）和线路回声消除（Line Echo Cancellation, LEC）。声学回音是由于在免提或者会议应用中，扬声器的声音多次反馈到麦克风引起的；线路回音是由于物理电子线路的二四线匹配耦合引起的。

回声消除需要回声的近端输入和参考帧（回声）数据。回音消除使用的是单声道.

回音消除是消除或移除本地话筒中的远端的音频信号来阻止远端的声音返回去。

常见回声消除算法库使用的是webrtc库

### 高通滤波

主要负责去除低频噪音（20-200Hz）
采样率8KHz：滤波150Hz以下频段
采样率16KHz:滤波400Hz以下频段 

20HZ--20000HZ是耳朵能听到的频率：
人声：
男：低音82～392Hz，基准音区64～523Hz，男中音123～493Hz，男高音164～698Hz
女：低音82～392Hz，基准音区160～1200Hz
女低音123～493Hz，女高音220～1.1KHz

### 噪声消除（抑制）--webrtc[NS]

WebRtc自带音频隆晚模块,效果良好。webrtc的NS在业内还是赫赫有名的,通过实际对比测试,我们发现webrtc的降噪的确是性能和稳定性都要高于同类开源算法。

webrtc的ns原理是这样的:把启动前50顿的数据拿来构建噪声模型,把启动前200顿的信号强度用来计算归一化的频谱差值计算。根据这两个模型使用概率目的函数来计算出每顿的信噪比并区分出噪声和声音。然后根据计算出的信噪比在频域使用维纳滤波器对噪声信号进行噪声消除,最后在根据降噪前后的能量比和信号噪声似然比对降噪后的数据进行修复和调整后输出。

webrtc的NS使用分析: webrtc的降噪支持三种采样率, 8k, 16k和32k,其它的采样率的降噪可以通过瞎采样来完成。降噪模式有四种:分别是,0.1,2,3四种模式的降噪量依次增加,笔者亲自测过,一般是2比较好,对声音损失小,降噪效果又不错。还有个比较重要的参数就是噪声估计模型宏定义,如下所示,推荐在系统计算能力够的情况下使用第三种,效果最好。

```c
#define PROCESS_FLOW_0 // Use the traditional method.
#define PROCESS_FLOW_1 // Use traditional with DD estimate of prior SNR.
#define PROCESS FLOW 2 // Use the new method of speech/noise classification.
```

